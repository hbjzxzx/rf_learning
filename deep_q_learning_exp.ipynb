{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "\n",
    "from deep_q import DeepQFunc, DeepQFuncTrainer, DeepQFuncTester, ReplayBuffer, Discrete1ContinuousAction\n",
    "from env import Env\n",
    "from utils import clear_target_path, show_gif_on_jupyternb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用CarPole-V1 环境，测试简单的Deep Q 如何处理连续的State空间和离散的Action空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action num: 2, space: Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n"
     ]
    }
   ],
   "source": [
    "GYM_ENV_NAME = 'CartPole-v1'\n",
    "_train_gym_env = gym.make(GYM_ENV_NAME)\n",
    "env = Env(_train_gym_env)\n",
    "\n",
    "# 打印查看环境的动作空间和状态空间 \n",
    "action_nums, state_space = _train_gym_env.action_space.n, _train_gym_env.observation_space\n",
    "print(f'action num: {action_nums}, space: {state_space}')\n",
    "\n",
    "TRAIN_EPOCH = 800\n",
    "HIDDEN_DIM = 256\n",
    "LEARNING_RATE = 2e-3\n",
    "GAMMA = 0.99\n",
    "\n",
    "# 使用指数递减的epsilon-greedy策略\n",
    "START_EPSILON = 0.5\n",
    "END_EPSILON = 0.05\n",
    "DECAY_RATE = 0.99\n",
    "EPSILON_LIST = [max(START_EPSILON * (DECAY_RATE ** i), END_EPSILON) for i in range(TRAIN_EPOCH)]\n",
    "\n",
    "LOG_PATH = Path('./run/logs/cartpoleV1/run_normal')\n",
    "MODEL_PATH = Path('./run/model/cartpoleV1/model.pth')\n",
    "TEST_OUTPUT_PATH = Path('./run/test_result/cartpoleV1')\n",
    "\n",
    "# _USE_CUDA = True and torch.cuda.is_available()\n",
    "_USE_CUDA = False and torch.cuda.is_available()\n",
    "\n",
    "q_func = DeepQFunc(state_space.shape[0], \n",
    "                   action_nums, \n",
    "                   hidden_dim=HIDDEN_DIM, \n",
    "                   device=torch.device('cuda') if _USE_CUDA else None)\n",
    "\n",
    "\n",
    "replay_buffer = ReplayBuffer(10000)\n",
    "q_func_trainer = DeepQFuncTrainer(q_func=q_func,\n",
    "                                  env=env,\n",
    "                                  replay_buffer=replay_buffer,\n",
    "                                  learning_rate=LEARNING_RATE,\n",
    "                                  batch_size=64,\n",
    "                                  gamma=GAMMA,\n",
    "                                  epsilon_list=EPSILON_LIST,\n",
    "                                  logger_folder=LOG_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_target_path(LOG_PATH)\n",
    "clear_target_path(MODEL_PATH)\n",
    "print(f'start training, now datetime: {datetime.datetime.now()}')\n",
    "q_func_trainer.train(train_epoch=TRAIN_EPOCH, \n",
    "                     max_steps=1000, \n",
    "                     minimal_replay_size_to_train=64 * 10,\n",
    "                     target_q_update_freq=10)\n",
    "print(f'end training, saving model to: {MODEL_PATH}, now datetime: {datetime.datetime.now()}')\n",
    "\n",
    "q_func.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'run\\\\model\\\\cartpoleV1\\\\model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m q_test_func \u001b[38;5;241m=\u001b[39m \u001b[43mDeepQFunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m _render_env \u001b[38;5;241m=\u001b[39m Env(gym\u001b[38;5;241m.\u001b[39mmake(GYM_ENV_NAME, render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb_array_list\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      3\u001b[0m q_func_tester \u001b[38;5;241m=\u001b[39m DeepQFuncTester(\n\u001b[0;32m      4\u001b[0m     q_func\u001b[38;5;241m=\u001b[39mq_func\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      5\u001b[0m     env\u001b[38;5;241m=\u001b[39m_render_env\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32mf:\\ws\\rf_learning\\deep_q.py:138\u001b[0m, in \u001b[0;36mDeepQFunc.from_file\u001b[1;34m(cls, path, device)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_file\u001b[39m(\u001b[38;5;28mcls\u001b[39m, path: Path, device: Optional[torch\u001b[38;5;241m.\u001b[39mdevice]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 138\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m     action_nums \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta_info\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maction_nums\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    140\u001b[0m     state_dim \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta_info\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dim\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mf:\\conda\\envs\\quant\\Lib\\site-packages\\torch\\serialization.py:1003\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1001\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1003\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1004\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1005\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mf:\\conda\\envs\\quant\\Lib\\site-packages\\torch\\serialization.py:448\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 448\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    450\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mf:\\conda\\envs\\quant\\Lib\\site-packages\\torch\\serialization.py:429\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'run\\\\model\\\\cartpoleV1\\\\model.pth'"
     ]
    }
   ],
   "source": [
    "q_test_func = DeepQFunc.from_file(MODEL_PATH)\n",
    "_render_env = Env(gym.make(GYM_ENV_NAME, render_mode='rgb_array_list'))\n",
    "q_func_tester = DeepQFuncTester(\n",
    "    q_func=q_func.to('cpu'),\n",
    "    env=_render_env\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_GIF = TEST_OUTPUT_PATH / 'result.gif'\n",
    "clear_target_path(RESULT_GIF)\n",
    "\n",
    "q_func_tester.test(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_func_from_checkpoint = DeepQFunc(state_space.shape[0], \n",
    "                   action_nums, \n",
    "                   hidden_dim=HIDDEN_DIM)\n",
    "q_func_from_checkpoint.load(Path('./model/trained_for_cartpole.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_func_tester = DeepQFuncTester(\n",
    "    q_func=q_func_from_checkpoint.to('cpu'),\n",
    "    env=_render_env\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_func_tester.test(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用Pendulum-v1 测试Double Q Learning对Q值系统高估的处理能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GYM_ENV_NAME = 'Pendulum-v1'\n",
    "_train_gym_env = gym.make(GYM_ENV_NAME)\n",
    "\n",
    "# 打印查看环境的动作空间和状态空间 \n",
    "action_space, state_space = _train_gym_env.action_space, _train_gym_env.observation_space\n",
    "print(f'action: {action_space}, space: {state_space}')\n",
    "\n",
    "BINS = 11\n",
    "\n",
    "\n",
    "TRAIN_EPOCH = 1000\n",
    "HIDDEN_DIM = 256\n",
    "LEARNING_RATE = 2e-3\n",
    "GAMMA = 0.99\n",
    "\n",
    "# 使用指数递减的epsilon-greedy策略\n",
    "START_EPSILON = 0.5\n",
    "END_EPSILON = 0.05\n",
    "DECAY_RATE = 0.99\n",
    "EPSILON_LIST = [max(START_EPSILON * (DECAY_RATE ** i), END_EPSILON) for i in range(TRAIN_EPOCH)]\n",
    "\n",
    "\n",
    "log_path = Path('./logs/pendulum/run_dqn')\n",
    "if log_path.exists():\n",
    "    shutil.rmtree(log_path)\n",
    "\n",
    "# _USE_CUDA = True and torch.cuda.is_available()\n",
    "_USE_CUDA = False and torch.cuda.is_available()\n",
    "\n",
    "q_func = DeepQFunc(state_space.shape[0], \n",
    "                   BINS, \n",
    "                   hidden_dim=HIDDEN_DIM, \n",
    "                   device=torch.device('cuda') if _USE_CUDA else None)\n",
    "\n",
    "env = Env(_train_gym_env)\n",
    "\n",
    "replay_buffer = ReplayBuffer(10000)\n",
    "q_func_trainer = DeepQFuncTrainer(q_func=q_func, \n",
    "                                  env=env,\n",
    "                                  replay_buffer=replay_buffer,\n",
    "                                  learning_rate=LEARNING_RATE,\n",
    "                                  batch_size=64,\n",
    "                                  gamma=GAMMA,\n",
    "                                  epsilon_list=EPSILON_LIST,\n",
    "                                  logger_folder=log_path,\n",
    "                                  action_converter=Discrete1ContinuousAction(action_space.low, action_space.high, BINS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_func_trainer.train(train_epoch=TRAIN_EPOCH, \n",
    "                     max_steps=1000, \n",
    "                     minimal_replay_size_to_train=64 * 10,\n",
    "                     target_q_update_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_render_env = Env(gym.make(GYM_ENV_NAME, render_mode='human'))\n",
    "q_func_tester = DeepQFuncTester(\n",
    "    q_func=q_func.to('cpu'),\n",
    "    env=_render_env,\n",
    "    action_converter=Discrete1ContinuousAction(action_space.low, action_space.high, BINS)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_func_tester.test(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用Double DQN 进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_q import DoubleQFuncTrainer\n",
    "\n",
    "log_path = Path('./logs/pendulum/run_double_dqn3')\n",
    "if log_path.exists():\n",
    "    shutil.rmtree(log_path)\n",
    "\n",
    "q_func2 = DeepQFunc(state_space.shape[0], \n",
    "                   BINS, \n",
    "                   hidden_dim=HIDDEN_DIM, \n",
    "                   device=torch.device('cuda') if _USE_CUDA else None)\n",
    "\n",
    "replay_buffer = ReplayBuffer(10000)\n",
    "q_func_trainer = DoubleQFuncTrainer(q_func=q_func2, \n",
    "                                  env=env,\n",
    "                                  replay_buffer=replay_buffer,\n",
    "                                  learning_rate=LEARNING_RATE,\n",
    "                                  batch_size=64,\n",
    "                                  gamma=GAMMA,\n",
    "                                  epsilon_list=EPSILON_LIST,\n",
    "                                  logger_folder=log_path,\n",
    "                                  action_converter=Discrete1ContinuousAction(action_space.low, action_space.high, BINS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_func_trainer.train(train_epoch=TRAIN_EPOCH, \n",
    "                     max_steps=1000, \n",
    "                     minimal_replay_size_to_train=64 * 10,\n",
    "                     target_q_update_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_render_env = Env(gym.make(GYM_ENV_NAME, render_mode='human'))\n",
    "q_func_tester = DeepQFuncTester(\n",
    "    q_func=q_func2.to('cpu'),\n",
    "    env=_render_env,\n",
    "    action_converter=Discrete1ContinuousAction(action_space.low, action_space.high, BINS)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_func_tester.test(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
